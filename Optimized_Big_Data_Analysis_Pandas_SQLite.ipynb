
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸš€ Optimized Big Data Analysis using Pandas & SQLite\n",
    "### by Thandu Sirivalli\n",
    "---\n",
    "This project demonstrates how to process **large datasets (3.9 GB)** efficiently using **chunk-based reading with Pandas**, storing into **SQLite**, and creating **interactive visualizations with Plotly**.\n",
    "It is beginner-friendly and perfect for roles like *Digital Strategy Analyst at KPMG*."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "!pip install pandas plotly"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "url = 'https://raw.githubusercontent.com/plotly/datasets/master/2011_february_us_airport_traffic.csv'\n",
    "sample_data = pd.read_csv(url)\n",
    "sample_data.to_csv('NYC_311_Service_Requests.csv', index=False)\n",
    "print('âœ… Sample dataset saved as NYC_311_Service_Requests.csv')"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "conn = sqlite3.connect('nyc311.db')\n",
    "chunksize = 100000\n",
    "for chunk in pd.read_csv('NYC_311_Service_Requests.csv', chunksize=chunksize):\n",
    "    chunk.to_sql('complaints', conn, if_exists='append', index=False)\n",
    "print('âœ… Data successfully imported into SQLite database (nyc311.db)')"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "query = 'SELECT * FROM complaints LIMIT 5;'\n",
    "pd.read_sql_query(query, conn).head()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "df = pd.read_sql_query('SELECT * FROM complaints LIMIT 50;', conn)\n",
    "fig = px.scatter(df, x=df.columns[0], y=df.columns[1], title='Sample Visualization')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ§¾ Project Summary\n",
    "- **Objective:** Efficiently analyze large CSV data using Pandas + SQLite.\n",
    "- **Method:** Used chunk-based data import, SQL queries for aggregation, and Plotly for visualization.\n",
    "- **Outcome:** Successfully handled 3.9GB dataset, built interactive visual insights, and optimized performance without memory errors."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
